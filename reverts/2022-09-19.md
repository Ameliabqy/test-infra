# Week of 2022-09-19 to 2022-09-26

### Weird

- [Revert "Use fallback approach for nested matmul (#85311)"](https://github.com/pytorch/pytorch/commit/caa0ab557dd10e04ca413c1508f76ec8ae5adea3) by [comment](https://github.com/pytorch/pytorch/pull/85311#issuecomment-1254315069)
- [Revert "Turn on aliasing tests for fake backwards, Fix Batch norm running mean/var decomp aliasing (#85471)"](https://github.com/pytorch/pytorch/commit/3b195fd33e5149daac89fff5e9f9336cdafe004d) by [comment](https://github.com/pytorch/pytorch/pull/85471#issuecomment-1256457874)
- [Revert "test in parallel at file granularity (#84961)"](https://github.com/pytorch/pytorch/commit/3dce26635f1bbab4bc96801e3cfd7ce728ba78b9) by [comment](https://github.com/pytorch/pytorch/pull/84961#issuecomment-1254186492)

### No Signal

- [Revert "[pytorch] cuBLAS addmm malfunction test (#85084)"](https://github.com/pytorch/pytorch/commit/2fb820455cc7b6d8f67e303098ffbcf4aac791f8) by [comment](https://github.com/pytorch/pytorch/pull/85084#issuecomment-1253972033)
- [Revert "[Profiler] Make `LibKinetoClient::stop()` directly call `ProfilerStateBase::pop` (#83965)"](https://github.com/pytorch/pytorch/commit/f0a084f3db544ec7db2f56d29ad9dcaa4619bf5a) by [comment](https://github.com/pytorch/pytorch/pull/83965#issuecomment-1255639872)
- [Revert "Legalize BFloat16 in NNC. (#83988)"](https://github.com/pytorch/pytorch/commit/6ed90379a848e1ff1422fb906253e38683c25c90) by [comment](https://github.com/pytorch/pytorch/pull/83988#issuecomment-1251518434)
- [Revert "Reduce memory usage requirement of `test_warp_softmax_64bit_indexing` in `test_nn.py` (#85037)"](https://github.com/pytorch/pytorch/commit/53fdd60635710a7a9f1c2a3eb1115f51b1247e94) by [comment](https://github.com/pytorch/pytorch/pull/85037#issuecomment-1251695869)
- [Revert "Create a quantized version ReLU function for CUDA (#85502)"](https://github.com/pytorch/pytorch/commit/41be45f0f4c6db2755be907db4f4a1665fe312e0) by [comment](https://github.com/pytorch/pytorch/pull/85502#issuecomment-1256958717)
- [Revert "add amp tests (#85434)"](https://github.com/pytorch/pytorch/commit/eb570ab7d0fd5df88fccf90cdadc581c722d20ef) by [comment](https://github.com/pytorch/pytorch/pull/85434#issuecomment-1256460688)
- [Revert "Improve and expose cpp_backtrace to python binding (#84896)"](https://github.com/pytorch/pytorch/commit/3122a96ee45507e8d33f265410222e69cc66677a) by [comment](https://github.com/pytorch/pytorch/pull/84896#issuecomment-1253150645)
- [Revert "[CUBLAS][CUDA GRAPHS] (re-open of #83461) Explicitly set the workspace for cuBLAS handles (#85292)"](https://github.com/pytorch/pytorch/commit/0ac6311356d21d052d2ca070b6f81706339deafb) by [comment](https://github.com/pytorch/pytorch/pull/85292#issuecomment-1254041013)
- [Revert "Add FakeCrossRef tests for backwards, Fix Layer Norm Backward Decomp (#85417)"](https://github.com/pytorch/pytorch/commit/d10de31cc833f1defa2cb64fef3c27f657a3dee2) by [comment](https://github.com/pytorch/pytorch/pull/85417#issuecomment-1256463953)
- [Revert "Exposing native _scaled_dot_product_attention to torch.nn (#85044)"](https://github.com/pytorch/pytorch/commit/a3dc338ee1b30aa1f59f36b3ba4c98d6a30a8600) by [comment](https://github.com/pytorch/pytorch/pull/85044#issuecomment-1253381129)
- [Revert "Land "Make ceil,floor,round,trunc handle integers" (#85144)"](https://github.com/pytorch/pytorch/commit/7234eb06f73f0e2c0aaa02727aee4afb5300ff1a) by [comment](https://github.com/pytorch/pytorch/pull/85144#issuecomment-1251408219)

### Ignored Signal

- [Revert "Python stack tracing OD flow (part 1) (#84362)"](https://github.com/pytorch/pytorch/commit/35088f283e5a93c6775e65e19d34093bdfb101e1) by [comment](https://github.com/pytorch/pytorch/pull/84362#issuecomment-1251797371)

### GHFirst

- [Revert "[mkldnn_matmul] enable mkldnn matmul for aarch64 bf16 devices (#83671)"](https://github.com/pytorch/pytorch/commit/2e883d4655ce4ad85b1a2af5cf9908c0032549c5) by [comment](https://github.com/pytorch/pytorch/pull/83671#issuecomment-1256263353)
- [Revert "[mta] APEX style Fused Adam (#81705)"](https://github.com/pytorch/pytorch/commit/e505360eb8c21d713180d3e71add0513cb201581) by [comment](https://github.com/pytorch/pytorch/pull/81705#issuecomment-1255465796)
- [Revert "[fix] composite compliance: cumprod, _masked.cumprod, linalg.vander (#85330)"](https://github.com/pytorch/pytorch/commit/0217a8d049ec54d303ef39776cf28bc80954b8e1) by [comment](https://github.com/pytorch/pytorch/pull/85330#issuecomment-1254043376)

### Got @pytorchbot revert command, but no corresponding commit

- cannot find commit corresponding to @pytorchbot revert comment by [comment](https://github.com/pytorch/pytorch/pull/81969#issuecomment-1254056739)

### Not through pytorchbot

- [Revert "Add FakeCrossRef tests for backwards, Fix Layer Norm Backward Decomp (#85417)"](https://github.com/pytorch/pytorch/commit/5043457a8ed07e06961c3b92579b856ed2bc9f6f)
- [Revert D39583438: Multisect successfully blamed D39583438 for test or build failures (#85277)](https://github.com/pytorch/pytorch/commit/86d8c61c7c122ede1628f967277073231f92c744)
# Week of 2022-09-19 to 2022-09-26

### Weird

- [Revert "Use fallback approach for nested matmul (#85311)"](https://github.com/pytorch/pytorch/commit/caa0ab557dd10e04ca413c1508f76ec8ae5adea3)
  - broke lots of builds https://hud.pytorch.org/pytorch/pytorch/commit/7c31f6e67213cbe773b0e2556f880f6ce2449fc3 even though the pr was green ([comment](https://github.com/pytorch/pytorch/pull/85311#issuecomment-1254315069))
  - probably a landrace
- [Revert "Turn on aliasing tests for fake backwards, Fix Batch norm running mean/var decomp aliasing (#85471)"](https://github.com/pytorch/pytorch/commit/3b195fd33e5149daac89fff5e9f9336cdafe004d)
  - stacked prs https://github.com/pytorch/pytorch/pull/85417 and https://github.com/pytorch/pytorch/pull/85434 broke trunk, reverting this so i can revert the others ([comment](https://github.com/pytorch/pytorch/pull/85471#issuecomment-1256457874))
- [Revert "test in parallel at file granularity (#84961)"](https://github.com/pytorch/pytorch/commit/3dce26635f1bbab4bc96801e3cfd7ce728ba78b9)
  - makes test_forward_ad_nn_functional_max_unpool2d_cuda_float32 flakily unexpectedly pass ([comment](https://github.com/pytorch/pytorch/pull/84961#issuecomment-1254186492))

### No Signal

- [Revert "[pytorch] cuBLAS addmm malfunction test (#85084)"](https://github.com/pytorch/pytorch/commit/2fb820455cc7b6d8f67e303098ffbcf4aac791f8)
  - broke tests on trunk, https://github.com/pytorch/pytorch/actions/runs/3098347639/jobs/5017166419 ([comment](https://github.com/pytorch/pytorch/pull/85084#issuecomment-1253972033))
- [Revert "[Profiler] Make `LibKinetoClient::stop()` directly call `ProfilerStateBase::pop` (#83965)"](https://github.com/pytorch/pytorch/commit/f0a084f3db544ec7db2f56d29ad9dcaa4619bf5a)
  - broke internal on-demand tracing: S296407 ([comment](https://github.com/pytorch/pytorch/pull/83965#issuecomment-1255639872))
- [Revert "Legalize BFloat16 in NNC. (#83988)"](https://github.com/pytorch/pytorch/commit/6ed90379a848e1ff1422fb906253e38683c25c90)
  - broke slow tests in trunk, https://github.com/pytorch/pytorch/actions/runs/3084421000/jobs/4986706931 ([comment](https://github.com/pytorch/pytorch/pull/83988#issuecomment-1251518434))
- [Revert "Reduce memory usage requirement of `test_warp_softmax_64bit_indexing` in `test_nn.py` (#85037)"](https://github.com/pytorch/pytorch/commit/53fdd60635710a7a9f1c2a3eb1115f51b1247e94)
  - broke test_warp_softmax_64bit_indexing_cuda_float32 and test_warp_softmax_64bit_indexing_cuda_float16 on rocm https://github.com/pytorch/pytorch/actions/runs/3085764744/jobs/4989643817 ([comment](https://github.com/pytorch/pytorch/pull/85037#issuecomment-1251695869))
- [Revert "Create a quantized version ReLU function for CUDA (#85502)"](https://github.com/pytorch/pytorch/commit/41be45f0f4c6db2755be907db4f4a1665fe312e0)
  - Sorry, reverting as 10.2 builds on trunk broke due to this change, see https://hud.pytorch.org/pytorch/pytorch/commit/93a53ff4d92c883d87cc7aee35af719039b481a8 ([comment](https://github.com/pytorch/pytorch/pull/85502#issuecomment-1256958717))
- [Revert "add amp tests (#85434)"](https://github.com/pytorch/pytorch/commit/eb570ab7d0fd5df88fccf90cdadc581c722d20ef)
  - broke rocm and slow tests on trunk https://hud.pytorch.org/pytorch/pytorch/commit/c2f4bbe66918d167401ff5804c6b2d24fc6bda40 ([comment](https://github.com/pytorch/pytorch/pull/85434#issuecomment-1256460688))
- [Revert "Improve and expose cpp_backtrace to python binding (#84896)"](https://github.com/pytorch/pytorch/commit/3122a96ee45507e8d33f265410222e69cc66677a)
  - Broke libtorch and linux-binary-manywheel - https://hud.pytorch.org/pytorch/pytorch/commit/73fbca1ea6ecc08ae4455a12b68fc2ead93a088c ([comment](https://github.com/pytorch/pytorch/pull/84896#issuecomment-1253150645))
- [Revert "[CUBLAS][CUDA GRAPHS] (re-open of #83461) Explicitly set the workspace for cuBLAS handles (#85292)"](https://github.com/pytorch/pytorch/commit/0ac6311356d21d052d2ca070b6f81706339deafb)
  - broke an internal test during shutdown. Re-submit with #85399 in stack ([comment](https://github.com/pytorch/pytorch/pull/85292#issuecomment-1254041013))
- [Revert "Add FakeCrossRef tests for backwards, Fix Layer Norm Backward Decomp (#85417)"](https://github.com/pytorch/pytorch/commit/d10de31cc833f1defa2cb64fef3c27f657a3dee2)
  - broke tests on trunk https://hud.pytorch.org/pytorch/pytorch/commit/78afa0cf0ca04ce437ca4b519f07c04e73fe0d4c ([comment](https://github.com/pytorch/pytorch/pull/85417#issuecomment-1256463953))
- [Revert "Exposing native _scaled_dot_product_attention to torch.nn (#85044)"](https://github.com/pytorch/pytorch/commit/a3dc338ee1b30aa1f59f36b3ba4c98d6a30a8600)
  - This breaks CUDA 10.2 in trunk. We are deprecating CUDA 10.2, but it is still here in the mean time ([comment](https://github.com/pytorch/pytorch/pull/85044#issuecomment-1253381129))
- [Revert "Land "Make ceil,floor,round,trunc handle integers" (#85144)"](https://github.com/pytorch/pytorch/commit/7234eb06f73f0e2c0aaa02727aee4afb5300ff1a)
  - broke slow tests in trunk  ex https://ossci-raw-job-status.s3.amazonaws.com/log/8433956087 ([comment](https://github.com/pytorch/pytorch/pull/85144#issuecomment-1251408219))
- [Revert "Add FakeCrossRef tests for backwards, Fix Layer Norm Backward Decomp (#85417)"
  - broke tests on trunk (and pull somehow) https://hud.pytorch.org/pytorch/pytorch/commit/9c77083965e1283763a83f72a3adf299281761e3 ([comment](https://github.com/pytorch/pytorch/pull/85417#issuecomment-1255212504)) 
  - edited because revert tracker got confused and placed this into the Not through pytorchbot section because this PR got reverted twice

### Ignored Signal

- [Revert "Python stack tracing OD flow (part 1) (#84362)"](https://github.com/pytorch/pytorch/commit/35088f283e5a93c6775e65e19d34093bdfb101e1)
  - Broke CUDA-10.2 tests, see https://hud.pytorch.org/pytorch/pytorch/commit/1f4f05e59c4cd72dfff9755629f7cc23f8df7abe ([comment](https://github.com/pytorch/pytorch/pull/84362#issuecomment-1251797371))

### GHFirst

- [Revert "[mkldnn_matmul] enable mkldnn matmul for aarch64 bf16 devices (#83671)"](https://github.com/pytorch/pytorch/commit/2e883d4655ce4ad85b1a2af5cf9908c0032549c5)
  - breaking meta internal builds where cpuinfo_has_arm_bf16 is not defined ([comment](https://github.com/pytorch/pytorch/pull/83671#issuecomment-1256263353))
- [Revert "[mta] APEX style Fused Adam (#81705)"](https://github.com/pytorch/pytorch/commit/e505360eb8c21d713180d3e71add0513cb201581)
  - broke internal builds, details to come ([comment](https://github.com/pytorch/pytorch/pull/81705#issuecomment-1255465796))
- [Revert "[fix] composite compliance: cumprod, _masked.cumprod, linalg.vander (#85330)"](https://github.com/pytorch/pytorch/commit/0217a8d049ec54d303ef39776cf28bc80954b8e1)
  - a PR this is based on got reverted, rebase and reland ([comment](https://github.com/pytorch/pytorch/pull/85330#issuecomment-1254043376))

### Got @pytorchbot revert command, but no corresponding commit

- cannot find commit corresponding to @pytorchbot revert comment
  - a PR this is based on got reverted, rebase and reland ([comment](https://github.com/pytorch/pytorch/pull/81969#issuecomment-1254056739))

### Not through pytorchbot
- [Revert D39583438: Multisect successfully blamed D39583438 for test or build failures (#85277)](https://github.com/pytorch/pytorch/commit/86d8c61c7c122ede1628f967277073231f92c744)
